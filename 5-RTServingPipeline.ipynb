{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline de Aplicación en Tiempo Real\n",
    "Definimos un pipeline de aplicación que realiza las siguientes acciones:\n",
    "\n",
    "- Recibe una solicitud del usuario.\n",
    "\n",
    "- Enriquece la solicitud con características en tiempo real obtenidas del feature store.\n",
    "\n",
    "- Envía las características enriquecidas a un ensamble de modelos (three-legged ensemble) que utiliza los modelos recientemente entrenados.\n",
    "\n",
    "### Ventajas de MLRun en el Desarrollo de Pipelines\n",
    "\n",
    "Construir un pipeline de este tipo tradicionalmente requeriría:\n",
    "\n",
    "- Implementar múltiples microservicios.\n",
    "\n",
    "- Escribir lógica compleja para gestionar el procesamiento en tiempo real, el enriquecimiento de datos y las predicciones.\n",
    "\n",
    "Con MLRun, este proceso se simplifica considerablemente:\n",
    "\n",
    "- Definición en pocas líneas de código: Puedes configurar todo el pipeline sin necesidad de construir microservicios adicionales.\n",
    "\n",
    "- Despliegue automático: El pipeline se implementa como funciones serverless elásticas, escalables según la demanda.\n",
    "\n",
    "#### Funcionalidades Automáticas del Framework de Serving de MLRun\n",
    "\n",
    "- Imputación de características en tiempo real: Automatiza el procesamiento y asegura que las características necesarias estén disponibles al momento de las predicciones.\n",
    "\n",
    "- Monitoreo de modelos: Supervisa el rendimiento y comportamiento de los modelos desplegados, detectando posibles desviaciones (model drift).\n",
    "\n",
    "Este enfoque no solo simplifica el desarrollo, sino que también asegura una integración robusta para manejar solicitudes en tiempo real sin necesidad de escribir código adicional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlrun\n",
    "import numpy as np\n",
    "from cloudpickle import load\n",
    "from mlrun.serving.v2_serving import V2ModelServer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (DatabaseError('database disk image is malformed')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "project = mlrun.load_project(\n",
    "    name=\"fraud-demo\",\n",
    "    context=\"./\",\n",
    "    user_project=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definiendo una clase de servicio de modelo personalizada\n",
    "\n",
    "MLRun tiene muchas clases de servicio de modelo integradas para diferentes frameworks (Sklearn, Xgboost, PyTorch, TensorFlow, ONNX, modelos de Hugging Face, etc.). También puedes construir tu propia clase de servicio de modelo personalizada, como se muestra en el Ejemplo 7-24. La clase de servicio debe admitir el método load() para cargar el modelo y el método predict() para hacer una predicción. Puedes leer la documentación de MLRun para ver todos los hooks y el uso avanzado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlrun: start-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierModel(V2ModelServer):\n",
    "    \n",
    "    def load(self):\n",
    "        \"\"\"load and initialize the model and/or other elements\"\"\"\n",
    "        model_file, extra_data = self.get_model('.pkl')\n",
    "        self.model = load(open(model_file, 'rb'))\n",
    "        \n",
    "    def predict(self, body: dict) -> list:\n",
    "        \"\"\"Generate model predictions from sample\"\"\"\n",
    "        print(f\"Input -> {body['inputs']}\")\n",
    "        feats = np.asarray(body['inputs'])\n",
    "        result: np.ndarray = self.model.predict(feats)\n",
    "        return result.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlrun: end-code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building an Application Pipeline with Enrichment and Ensemble\n",
    "\n",
    "MLRun serving can produce managed real-time serverless pipelines from various tasks, including MLRun models or standard model files. The pipelines use the Nuclio real-time serverless engine, which can be deployed anywhere. Nuclio is a high-performance open-source serverless framework focused on data, I/O, and compute-intensive workloads.\n",
    "\n",
    "The EnrichmentVotingEnsemble router class auto-enriches the request with data from the feature store. The router input accepts a list of inference requests (each request can be a dict or list of incoming features/keys). It enriches the request with data from the specified feature vector (feature_vector_uri), forwards the vector to one or more models in an ensemble, and returns an aggregated prediction value (for example, the average result across the three models).\n",
    "The features can often have null values (None, NaN, Inf). The Enrichment_ routers can substitute the null value with fixed or statistical value per fea ture. This is done through the `impute_policy` parameter, which accepts the impute policy per feature (where * is used to specify the default). The value can be a fixed number for constants or $mean, $max, $min, $std, $count for statistical values to substitute the value with the equivalent feature stats (taken from the feature store).\n",
    "The code in Example 7-24 defines a new serving function with the ClassifierModel class code (in serving.py) and a router topology (using the EnrichmentVotingEnsem ble router class) with three child models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construcción de un Pipeline de Aplicación con Enriquecimiento y Ensamble\n",
    "\n",
    "El framework de serving de MLRun permite construir pipelines serverless gestionados en tiempo real que combinan diversas tareas, incluidos modelos de MLRun o archivos de modelos estándar. Estos pipelines utilizan el motor serverless en tiempo real Nuclio, un framework de alto rendimiento, diseñado para tareas intensivas en datos, E/S y cómputo, que puede desplegarse en cualquier entorno.\n",
    "\n",
    "### Clases de Enriquecimiento y Ensamble\n",
    "\n",
    "La clase EnrichmentVotingEnsemble actúa como un enrutador para:\n",
    "\n",
    "- Enriquecer las solicitudes con datos en tiempo real provenientes del feature store.\n",
    "\n",
    "- Procesar solicitudes de inferencia: Admite una lista de solicitudes de inferencia, donde cada solicitud puede ser un diccionario o una lista de características/llaves.\n",
    "\n",
    "- Envío al ensamble de modelos: Utiliza las características enriquecidas y las envía a uno o más modelos del ensamble.\n",
    "\n",
    "- Predicción agregada: Devuelve un valor de predicción combinado, como el promedio de los resultados de los tres modelos del ensamble.\n",
    "\n",
    "#### Gestión de Valores Nulos\n",
    "\n",
    "Las características enriquecidas pueden contener valores nulos (None, NaN, Inf). Para manejar esto:\n",
    "\n",
    "Política de imputación (impute_policy): Permite sustituir valores nulos con un valor fijo o estadístico:\n",
    "\n",
    "- Valores fijos: Un número constante.\n",
    "\n",
    "- Valores estadísticos: $mean, $max, $min, $std, $count.\n",
    "\n",
    "Estos valores se obtienen directamente del feature store y se asignan a las características especificadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topología del Router\n",
    "\n",
    "Una nueva función de serving utilizando la clase ClassifierModel.\n",
    "\n",
    "Una topología de router basada en la clase EnrichmentVotingEnsemble:\n",
    "\n",
    "- Configurada con tres modelos secundarios (child models).\n",
    "\n",
    "- Realiza predicciones agregadas con enriquecimiento automático desde el feature store.\n",
    "\n",
    "#### Ventajas del Enfoque\n",
    "\n",
    "- Automatización del enriquecimiento: Simplifica la integración de datos en tiempo real.\n",
    "\n",
    "- Gestión eficiente de valores nulos: Mejora la calidad de los datos utilizados para inferencias.\n",
    "\n",
    "- Escalabilidad y rendimiento: Al aprovechar Nuclio, se garantiza una solución serverless robusta y de alto rendimiento.\n",
    "\n",
    "Este pipeline permite manejar solicitudes en tiempo real de manera eficiente, enriqueciendo los datos automáticamente y combinando predicciones de múltiples modelos en una arquitectura escalable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('transaction_fraud_rf',\n",
       "  {'updated': '2024-10-08 13:21:47.319818+00:00',\n",
       "   'project': 'fraud-demo-felipe',\n",
       "   'key': 'model',\n",
       "   'tree': 'e27f0d6d-8f14-4642-abee-43b9867631ef',\n",
       "   'tag': 'latest',\n",
       "   'labels': {'workflow-id': 'e27f0d6d-8f14-4642-abee-43b9867631ef',\n",
       "    'framework': 'sklearn'},\n",
       "   'iter': 1,\n",
       "   'hash': 'd31c0e672e4ac97438e866612c9fb02c1a3a1732'}),\n",
       " ('transaction_fraud_xgboost',\n",
       "  {'updated': '2024-10-08 13:21:18.851606+00:00',\n",
       "   'project': 'fraud-demo-felipe',\n",
       "   'key': 'model',\n",
       "   'tree': 'e27f0d6d-8f14-4642-abee-43b9867631ef',\n",
       "   'tag': 'latest',\n",
       "   'labels': {'workflow-id': 'e27f0d6d-8f14-4642-abee-43b9867631ef',\n",
       "    'framework': 'sklearn'},\n",
       "   'iter': 2,\n",
       "   'hash': 'd40c64ec2d081899089ec7e34288c87a175a848f'}),\n",
       " ('transaction_fraud_adaboost',\n",
       "  {'updated': '2024-10-08 13:21:22.048244+00:00',\n",
       "   'project': 'fraud-demo-felipe',\n",
       "   'key': 'model',\n",
       "   'tree': 'e27f0d6d-8f14-4642-abee-43b9867631ef',\n",
       "   'tag': 'latest',\n",
       "   'labels': {'workflow-id': 'e27f0d6d-8f14-4642-abee-43b9867631ef',\n",
       "    'framework': 'sklearn'},\n",
       "   'iter': 3,\n",
       "   'hash': 'db02f4acce087779cbc634285ea1647206a5fc84'})]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(m.spec.db_key, m.metadata.to_dict()) for m in project.list_models('', tag='latest')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serving_fn = project.set_function('src/serving.py', name='test-function',\n",
    "                                  image=\"mlrun/mlrun\", kind=\"serving\")\n",
    "serving_fn.set_topology(\n",
    "    \"router\",\n",
    "    mlrun.serving.routers.EnrichmentVotingEnsemble(\n",
    "        feature_vector_uri=\"short\",\n",
    "        impute_policy={\"*\": \"$mean\"}),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: mlrun&#45;flow Pages: 1 -->\n",
       "<svg width=\"800pt\" height=\"196pt\"\n",
       " viewBox=\"0.00 0.00 799.73 196.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 192)\">\n",
       "<title>mlrun&#45;flow</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-192 795.73,-192 795.73,4 -4,4\"/>\n",
       "<!-- _start -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>_start</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"364.89,-152.05 367.04,-152.15 369.17,-152.3 371.26,-152.49 373.32,-152.74 375.33,-153.03 377.29,-153.36 379.18,-153.75 381,-154.18 382.74,-154.65 384.4,-155.16 385.98,-155.71 387.45,-156.31 388.83,-156.94 390.1,-157.61 391.27,-158.31 392.33,-159.04 393.28,-159.8 394.11,-160.59 394.83,-161.41 395.43,-162.25 395.92,-163.11 396.29,-163.99 396.55,-164.89 396.7,-165.8 396.74,-166.72 396.67,-167.65 396.5,-168.59 396.23,-169.53 395.87,-170.47 395.41,-171.41 394.86,-172.35 394.23,-173.28 393.52,-174.2 392.74,-175.11 391.89,-176.01 390.97,-176.89 389.99,-177.75 388.96,-178.59 387.87,-179.41 386.74,-180.2 385.57,-180.96 384.36,-181.69 383.12,-182.39 381.84,-183.06 380.54,-183.69 379.22,-184.29 377.87,-184.84 376.51,-185.35 375.13,-185.82 373.74,-186.25 372.34,-186.64 370.93,-186.97 369.51,-187.26 368.09,-187.51 366.66,-187.7 365.23,-187.85 363.79,-187.95 362.36,-188 360.92,-188 359.49,-187.95 358.05,-187.85 356.62,-187.7 355.19,-187.51 353.77,-187.26 352.35,-186.97 350.94,-186.64 349.54,-186.25 348.15,-185.82 346.77,-185.35 345.41,-184.84 344.06,-184.29 342.74,-183.69 341.44,-183.06 340.16,-182.39 338.92,-181.69 337.71,-180.96 336.54,-180.2 335.41,-179.41 334.32,-178.59 333.29,-177.75 332.31,-176.89 331.39,-176.01 330.54,-175.11 329.76,-174.2 329.05,-173.28 328.42,-172.35 327.87,-171.41 327.41,-170.47 327.05,-169.53 326.78,-168.59 326.61,-167.65 326.54,-166.72 326.58,-165.8 326.73,-164.89 326.99,-163.99 327.36,-163.11 327.85,-162.25 328.46,-161.41 329.17,-160.59 330.01,-159.8 330.95,-159.04 332.01,-158.31 333.18,-157.61 334.45,-156.94 335.83,-156.31 337.31,-155.71 338.88,-155.16 340.54,-154.65 342.28,-154.18 344.1,-153.75 345.99,-153.36 347.95,-153.03 349.96,-152.74 352.02,-152.49 354.11,-152.3 356.24,-152.15 358.39,-152.05 360.56,-152 362.72,-152 364.89,-152.05\"/>\n",
       "<text text-anchor=\"middle\" x=\"361.64\" y=\"-166.3\" font-family=\"Times,serif\" font-size=\"14.00\">start</text>\n",
       "</g>\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title></title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"388.64,-86.54 388.64,-101.46 372.82,-112 350.46,-112 334.64,-101.46 334.64,-86.54 350.46,-76 372.82,-76 388.64,-86.54\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"392.64,-84.4 392.64,-103.6 374.04,-116 349.25,-116 330.64,-103.6 330.64,-84.4 349.25,-72 374.04,-72 392.64,-84.4\"/>\n",
       "</g>\n",
       "<!-- _start&#45;&gt; -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>_start&#45;&gt;</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M361.64,-151.84C361.64,-144.16 361.64,-134.88 361.64,-126.05\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"365.14,-126.03 361.64,-116.03 358.14,-126.03 365.14,-126.03\"/>\n",
       "</g>\n",
       "<!-- transaction_fraud_rf -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>transaction_fraud_rf</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"104.64\" cy=\"-18\" rx=\"104.78\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"104.64\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">transaction_fraud_rf</text>\n",
       "</g>\n",
       "<!-- &#45;&gt;transaction_fraud_rf -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>&#45;&gt;transaction_fraud_rf</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M330.9,-84.15C290.22,-72.43 217.59,-51.52 165.59,-36.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"166.39,-33.14 155.81,-33.73 164.45,-39.86 166.39,-33.14\"/>\n",
       "</g>\n",
       "<!-- transaction_fraud_xgboost -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>transaction_fraud_xgboost</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"361.64\" cy=\"-18\" rx=\"133.78\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"361.64\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">transaction_fraud_xgboost</text>\n",
       "</g>\n",
       "<!-- &#45;&gt;transaction_fraud_xgboost -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>&#45;&gt;transaction_fraud_xgboost</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M361.64,-71.99C361.64,-64.06 361.64,-54.91 361.64,-46.48\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"365.14,-46.31 361.64,-36.31 358.14,-46.31 365.14,-46.31\"/>\n",
       "</g>\n",
       "<!-- transaction_fraud_adaboost -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>transaction_fraud_adaboost</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"652.64\" cy=\"-18\" rx=\"139.18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"652.64\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">transaction_fraud_adaboost</text>\n",
       "</g>\n",
       "<!-- &#45;&gt;transaction_fraud_adaboost -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>&#45;&gt;transaction_fraud_adaboost</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M392.78,-85.08C437.78,-73.64 522.21,-52.17 582.62,-36.81\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"583.65,-40.16 592.48,-34.3 581.92,-33.37 583.65,-40.16\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7fc6e54b5520>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for model in project.list_models('', tag='latest'):\n",
    "    name = model.spec.db_key\n",
    "    serving_fn.add_model(name, class_name=\"ClassifierModel\", model_path=model.uri)\n",
    "\n",
    "serving_fn.spec.graph.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test del Pipeline de Aplicación Localmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2024-10-08 13:41:43,004 [info] model transaction_fraud_rf was loaded\n",
      "> 2024-10-08 13:41:43,033 [info] model transaction_fraud_xgboost was loaded\n",
      "> 2024-10-08 13:41:43,064 [info] model transaction_fraud_adaboost was loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trying to unpickle estimator DecisionTreeClassifier from version 1.5.2 when using version 1.5.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "Trying to unpickle estimator RandomForestClassifier from version 1.5.2 when using version 1.5.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "Trying to unpickle estimator LogisticRegression from version 1.5.2 when using version 1.5.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "Trying to unpickle estimator AdaBoostClassifier from version 1.5.2 when using version 1.5.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n"
     ]
    }
   ],
   "source": [
    "local_server = serving_fn.to_mock_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input -> [[82.38333699999998, 176.010817, 0.0, 38.79236982490288, 134.16, 417.81, 11.0, 37.982727272727274, 134.16, 1275.0599999999997, 44.0, 28.978636363636358, 90.0, 1.0, 2.0]]\n",
      "Input -> [[82.38333699999998, 176.010817, 0.0, 38.79236982490288, 134.16, 417.81, 11.0, 37.982727272727274, 134.16, 1275.0599999999997, 44.0, 28.978636363636358, 90.0, 1.0, 2.0]]\n",
      "Input -> [[82.38333699999998, 176.010817, 0.0, 38.79236982490288, 134.16, 417.81, 11.0, 37.982727272727274, 134.16, 1275.0599999999997, 44.0, 28.978636363636358, 90.0, 1.0, 2.0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'f7f45c8d7e3a4c6993d6e10cc0f91acd',\n",
       " 'model_name': 'VotingEnsemble',\n",
       " 'outputs': [0],\n",
       " 'model_version': 'v1'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_id = 'C1000148617'\n",
    "\n",
    "local_server.test(path='/v2/models/infer',\n",
    "            body={'inputs': [[sample_id]]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Acceso Directo al Vector de Características en Tiempo Real\n",
    "\n",
    "Si prefieres acceder directamente a las características en tiempo real desde tu aplicación, en lugar de utilizar EnrichmentVotingEnsemble, puedes llamar al método get_online_feature_service() del feature store. Este método se utiliza internamente en la clase de enrutador EnrichmentVotingEnsemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlrun.feature_store as fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'amount_max_2h': 82.38333699999998,\n",
       "  'amount_max_12h': 134.16,\n",
       "  'amount_max_24h': 134.16,\n",
       "  'amount_count_2h': 0.0,\n",
       "  'amount_count_12h': 11.0,\n",
       "  'amount_count_24h': 44.0,\n",
       "  'amount_sum_2h': 176.010817,\n",
       "  'amount_sum_12h': 417.81,\n",
       "  'amount_sum_24h': 1275.0599999999997,\n",
       "  'es_transportation_sum_14d': 90.0,\n",
       "  'es_health_sum_14d': 1.0,\n",
       "  'es_otherservices_sum_14d': 2.0,\n",
       "  'amount_avg_2h': 38.79236982490288,\n",
       "  'amount_avg_12h': 37.982727272727274,\n",
       "  'amount_avg_24h': 28.978636363636358}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = fs.get_feature_vector('short:latest').get_online_feature_service(impute_policy={\"*\": \"$mean\"})\n",
    "\n",
    "sample_fv = svc.get([{'source': sample_id}])\n",
    "sample_fv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Despliegue de la Función en el Clúster de Kubernetes\n",
    "\n",
    "Una vez que hayas definido la función, puedes desplegarla en el clúster de Kubernetes. Al hacerlo, obtendrás una función con un disparador HTTP que puede ser llamada desde cualquier ubicación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2024-10-08 13:41:43,535 [info] Starting remote function deploy\n",
      "2024-10-08 13:41:43  (info) Deploying function\n",
      "2024-10-08 13:41:44  (info) Building\n",
      "2024-10-08 13:41:44  (info) Staging files and preparing base images\n",
      "2024-10-08 13:41:44  (warn) Using user provided base image, runtime interpreter version is provided by the base image\n",
      "2024-10-08 13:41:44  (info) Building processor image\n",
      "2024-10-08 13:42:49  (info) Build complete\n",
      "2024-10-08 13:43:13  (info) Function deploy complete\n",
      "> 2024-10-08 13:43:14,979 [info] Successfully deployed function: {\"external_invocation_urls\":[\"fraud-demo-felipe-test-function.default-tenant.app.cust-cs-illl--3-6-0.iguazio-cd2.com/\"],\"internal_invocation_urls\":[\"nuclio-fraud-demo-felipe-test-function.default-tenant.svc.cluster.local:8080\"]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'http://fraud-demo-felipe-test-function.default-tenant.app.cust-cs-illl--3-6-0.iguazio-cd2.com/'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serving_fn.set_tracking()\n",
    "project.set_model_monitoring_credentials(None, \"v3io\", \"v3io\", \"v3io\")\n",
    "\n",
    "serving_fn.deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test del server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2024-10-08 13:43:15,027 [info] Invoking function: {\"method\":\"POST\",\"path\":\"http://nuclio-fraud-demo-felipe-test-function.default-tenant.svc.cluster.local:8080/v2/models/infer\"}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'ee5635d0-bb82-4036-a71c-379696d9ed79',\n",
       " 'model_name': 'VotingEnsemble',\n",
       " 'outputs': [0],\n",
       " 'model_version': 'v1'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_id = 'C1000148617'\n",
    "\n",
    "model_inference_path = '/v2/models/infer'\n",
    "\n",
    "serving_fn.invoke(path='/v2/models/infer',\n",
    "                  body={'inputs': [[sample_id]]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulación de una solicitud de usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mlrun.get_dataitem(mlrun.get_sample_path(\"data/fraud-demo-mlrun-fs-docs/data.csv\")).as_df()\n",
    "\n",
    "data = data.sort_values(by='source', axis=0)[:10000]\n",
    "\n",
    "sample_ids = data['source'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice, uniform\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2024-10-08 13:43:19,205 [info] Invoking function: {\"method\":\"POST\",\"path\":\"http://nuclio-fraud-demo-felipe-test-function.default-tenant.svc.cluster.local:8080/v2/models/infer\"}\n",
      "{'id': 'efa462b4-36ed-4f63-8d4d-8d6474fff08d', 'model_name': 'VotingEnsemble', 'outputs': [0], 'model_version': 'v1'}\n",
      "> 2024-10-08 13:43:20,718 [info] Invoking function: {\"method\":\"POST\",\"path\":\"http://nuclio-fraud-demo-felipe-test-function.default-tenant.svc.cluster.local:8080/v2/models/infer\"}\n",
      "{'id': 'b930f851-fd9a-498a-8b7f-4e84f3bd42ec', 'model_name': 'VotingEnsemble', 'outputs': [0], 'model_version': 'v1'}\n",
      "> 2024-10-08 13:43:21,987 [info] Invoking function: {\"method\":\"POST\",\"path\":\"http://nuclio-fraud-demo-felipe-test-function.default-tenant.svc.cluster.local:8080/v2/models/infer\"}\n",
      "{'id': 'c064d2e8-377a-4384-9a47-7c5881f83b0a', 'model_name': 'VotingEnsemble', 'outputs': [0], 'model_version': 'v1'}\n",
      "> 2024-10-08 13:43:22,928 [info] Invoking function: {\"method\":\"POST\",\"path\":\"http://nuclio-fraud-demo-felipe-test-function.default-tenant.svc.cluster.local:8080/v2/models/infer\"}\n",
      "{'id': 'd4d6a214-fcf5-4c94-9551-db129c1f52f2', 'model_name': 'VotingEnsemble', 'outputs': [0], 'model_version': 'v1'}\n",
      "> 2024-10-08 13:43:23,263 [info] Invoking function: {\"method\":\"POST\",\"path\":\"http://nuclio-fraud-demo-felipe-test-function.default-tenant.svc.cluster.local:8080/v2/models/infer\"}\n",
      "{'id': '72419b36-0e6e-4ade-8b23-70b3407115d6', 'model_name': 'VotingEnsemble', 'outputs': [0], 'model_version': 'v1'}\n",
      "> 2024-10-08 13:43:24,141 [info] Invoking function: {\"method\":\"POST\",\"path\":\"http://nuclio-fraud-demo-felipe-test-function.default-tenant.svc.cluster.local:8080/v2/models/infer\"}\n",
      "{'id': 'aa27481c-5903-4f02-9ce4-5540fb45d775', 'model_name': 'VotingEnsemble', 'outputs': [0], 'model_version': 'v1'}\n",
      "> 2024-10-08 13:43:25,491 [info] Invoking function: {\"method\":\"POST\",\"path\":\"http://nuclio-fraud-demo-felipe-test-function.default-tenant.svc.cluster.local:8080/v2/models/infer\"}\n",
      "{'id': 'fdc379d7-7a9c-452b-91ac-93b29abaffab', 'model_name': 'VotingEnsemble', 'outputs': [0], 'model_version': 'v1'}\n",
      "> 2024-10-08 13:43:26,392 [info] Invoking function: {\"method\":\"POST\",\"path\":\"http://nuclio-fraud-demo-felipe-test-function.default-tenant.svc.cluster.local:8080/v2/models/infer\"}\n",
      "{'id': '015fbeab-7f98-4295-a05e-a2fb38d54b3a', 'model_name': 'VotingEnsemble', 'outputs': [0], 'model_version': 'v1'}\n",
      "> 2024-10-08 13:43:27,417 [info] Invoking function: {\"method\":\"POST\",\"path\":\"http://nuclio-fraud-demo-felipe-test-function.default-tenant.svc.cluster.local:8080/v2/models/infer\"}\n",
      "{'id': '59733a3f-ffc8-4828-88e7-0e46ff9a129a', 'model_name': 'VotingEnsemble', 'outputs': [0], 'model_version': 'v1'}\n",
      "> 2024-10-08 13:43:28,915 [info] Invoking function: {\"method\":\"POST\",\"path\":\"http://nuclio-fraud-demo-felipe-test-function.default-tenant.svc.cluster.local:8080/v2/models/infer\"}\n",
      "{'id': '05e984c5-556d-415d-a4f4-e3eb389f2213', 'model_name': 'VotingEnsemble', 'outputs': [0], 'model_version': 'v1'}\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    data_point = choice(sample_ids)\n",
    "    try:\n",
    "        resp = serving_fn.invoke(path=model_inference_path, body={'inputs': [[data_point]]})\n",
    "        print(resp)\n",
    "        sleep(uniform(0.2, 1.7))\n",
    "    except OSError:\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
